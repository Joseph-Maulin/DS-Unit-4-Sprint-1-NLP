{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S1-NLP-DS11",
      "language": "python",
      "name": "u4-s1-nlp-ds11"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "LS_DS_413_Document_Classification_Lecture.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ONIPJDrQra",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUgjrykurQrb",
        "colab_type": "text"
      },
      "source": [
        "# Document Classification (Prepare)\n",
        "\n",
        "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today's all about having fun and practicing your skills. The competition will begin\n",
        "\n",
        "## Learning Objectives\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLWgsmerQrb",
        "colab_type": "text"
      },
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqbXDERarQrc",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. \n",
        "\n",
        "*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) is transforming our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time. Train your vectorizer separately (ie out of the grid-searched pipeline). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PiOIt8rrQrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Statements\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY3F2UFOrQrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['talk.politics.misc',\n",
        "              'sci.space']\n",
        "\n",
        "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiPjyrdBrQrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e0fd2a2b-e164-4ff2-9a75-74818b1e8dd4"
      },
      "source": [
        "#print out data sample\n",
        "data['data'][2]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nMy opinion is this:  In a society whose economy is primarily based on \\ncapitalism, the role of government should be to provide those goods and \\nservices that need providing for the general public's good.  BUT government \\nshould supply those necessary goods and services only when it is impossible \\nfor a private enterprise (or individual) to make money from providing them.\\nI agree with some of the other posts that this train probably can not make \\nmoney and will rely heavily on State tax dollars.  \\n\\nThe question, I think, then becomes:  Do we, the general public, need the train?\\n\\nI certainly do not, nor will I ever, need this train in Lubbock, Texas.  With\\nthe inexpensive air travel provided between Dallas and Houston, I don't think\\npeople in Dallas or Houston need it either.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML8kE3zirQrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Pipeline Components\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRS7KaAorQrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the Pipeline\n",
        "pipe = Pipeline([\n",
        "                 #Vectorizer\n",
        "                 ('vect', vect),\n",
        "                 # Classifier\n",
        "                 ('clf', rfc)\n",
        "                ])\n",
        "\n",
        "# The pipeline puts together a bunch fit then transform,fit then predict. "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdJL-KL1rQrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "7c89f16c-1077-40d6-9460-d978e882ec0b"
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': ( 0.75, 1.0), # ignore words that occur in over 75% or don't ignore of docs\n",
        "    'vect__min_df': (.02, .05), # ignore words that occur in less 2% or 5% of docs\n",
        "    'vect__max_features': (500,1000), # only tokens with high tfid score\n",
        "    'clf__n_estimators':(5, 10,), # decision trees for classifier, typically 100s but increases training time\n",
        "    'clf__max_depth':(15,20) # limits depth of each individual tree. Stops overfitting.\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(data.data, data.target)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   24.1s\n",
            "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 2),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                                               n_jobs=None,\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=None,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': (15, 20),\n",
              "                         'clf__n_estimators': (5, 10),\n",
              "                         'vect__max_df': (0.75, 1.0),\n",
              "                         'vect__max_features': (500, 1000),\n",
              "                         'vect__min_df': (0.02, 0.05)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huXx7rkSrQru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "084d2e7e-df7f-4ddf-9e6e-4f2a116ff8d1"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8298309934722348"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9cZO5B_w4iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "9c76b65d-2958-4920-f5f9-2bfb3588a9ac"
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=0.75, max_features=1000,\n",
              "                                 min_df=0.02, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_p...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=20, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=10, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLN8TZ--xN5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f9930749-e03b-453c-f5ef-56387dc9c214"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__max_depth': 20,\n",
              " 'clf__n_estimators': 10,\n",
              " 'vect__max_df': 1.0,\n",
              " 'vect__max_features': 1000,\n",
              " 'vect__min_df': 0.02}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQrgdhfrrQrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "178a43bd-375d-499e-de03-dd17496c1743"
      },
      "source": [
        "# politics and space\n",
        "grid_search.predict(['This is a free society', 'Elections will be in November', \"Covid doesn't care what your political beliefs are.\", \"The team successfully launched their satellite into low-earth orbit\"])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re-kR-V_xdFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2b04aadd-5a47-4676-ec41-9afd2062beff"
      },
      "source": [
        "grid_search.predict_proba(['This is a free society', 'Elections will be in November', \"Covid doesn't care what your political beliefs are.\", \"The team successfully launched their satellite into low Earth orbit\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.393805  , 0.606195  ],\n",
              "       [0.64369526, 0.35630474],\n",
              "       [0.41288389, 0.58711611],\n",
              "       [0.72079909, 0.27920091]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "m0MukZakrQr0",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO1dk9SBrQr0",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve 75% Accuracy on your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZdGl9FwrQr1",
        "colab_type": "text"
      },
      "source": [
        "## Latent Semantic Indexing (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VFrj5TQrQr1",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_CWA5R8rQr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
        "                   algorithm='randomized',\n",
        "                   n_iter=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5qLoJp2rQr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = { \n",
        "    'lsi__svd__n_components': [10,100,250],\n",
        "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
        "    'clf__n_estimators':[5,10,20]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j07YyqlsrQr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSI\n",
        "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
        "\n",
        "\n",
        "# Pipe\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBVwl1dzrQr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pipe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOVH2EbErQsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit\n",
        "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(data.data, data.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Hb12GxrQsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvwg6InIrQsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "qGmEWWIjrQsJ",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GolxcCRTrQsJ",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewVIx4ScrQsK",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings with Spacy (Learn)\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAp8B5lYrQsK",
        "colab_type": "text"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6VTxIcRrQsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdr_tZR6rQsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"Two bananas in pyjamas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no095Iy2rQsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bananas_vector = doc.vector\n",
        "print(len(bananas_vector))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCsFBsuurQsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_vectors(docs):\n",
        "    return [nlp(doc).vector for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktSJcl9vrQsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = get_word_vectors(train['description'])\n",
        "\n",
        "len(X) == len(data.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL7dF7HBrQsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = get_word_vectors(test['description'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoymcTQ_rQsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc.fit(X, train['ratingCategory'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlUoAcYUrQsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc.score(X, train['ratingCategory'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhlxnRKMrQsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8lAkrHJrQse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['ratingCategory'] = rfc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmDU_IEYrQsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[['id', 'ratingCategory']].to_csv('testSolutionSubmission.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7SolrF4rQsj",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXAHmB2PrQsj",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Make a submission to Kaggle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB4h9GQFrQsj",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "To review this module: \n",
        "* Continue working on the Kaggle competition\n",
        "* Find another text classification task to work on"
      ]
    }
  ]
}